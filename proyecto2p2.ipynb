{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec2c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos y convertir a numÃ©ricos\n",
    "train_df = pd.read_csv(\"train_df.csv\")\n",
    "test_df = pd.read_csv(\"test_df.csv\")\n",
    "\n",
    "# Eliminar columnas no numÃ©ricas y convertir\n",
    "X_train = train_df.drop(columns=[\"paciente_id\", \"target\"]).apply(pd.to_numeric, errors=\"coerce\").dropna()\n",
    "y_train = train_df.loc[X_train.index, \"target\"].values.reshape(-1, 1)\n",
    "X_test = test_df.drop(columns=[\"paciente_id\"]).apply(pd.to_numeric, errors=\"coerce\").dropna()\n",
    "\n",
    "# Normalizar\n",
    "X_train_normalized = normalize(X_train.values.astype(np.float64))\n",
    "X_test_normalized = normalize(X_test.values.astype(np.float64))\n",
    "\n",
    "# AÃ±adir bias\n",
    "X_train_final = np.hstack([np.ones((X_train_normalized.shape[0], 1)), X_train_normalized])\n",
    "X_test_final = np.hstack([np.ones((X_test_normalized.shape[0], 1)), X_test_normalized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe9244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def compute_loss(y_true, y_pred):\n",
    "    m = y_true.shape[0]\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "\n",
    "def train_logistic_regression(X, y, lr=0.01, epochs=1000):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros((n, 1))\n",
    "    bias = 0\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        z = np.dot(X, theta) + bias\n",
    "        y_hat = sigmoid(z)\n",
    "\n",
    "        loss = compute_loss(y, y_hat)\n",
    "        loss_history.append(loss)\n",
    "\n",
    "        dz = y_hat - y\n",
    "        dw = np.dot(X.T, dz) / m\n",
    "        db = np.sum(dz) / m\n",
    "\n",
    "        theta -= lr * dw\n",
    "        bias -= lr * db\n",
    "\n",
    "    return theta, bias, loss_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bea8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, theta, bias, threshold=0.5):\n",
    "    probs = sigmoid(np.dot(X, theta) + bias)\n",
    "    return (probs >= threshold).astype(int)\n",
    "\n",
    "def compute_f1_score(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "    if tp + fp == 0 or tp + fn == 0:\n",
    "        return 0.0  # evitar divisiÃ³n por cero\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "def normalize(X):\n",
    "    norms = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    # Evitar divisiÃ³n por cero\n",
    "    norms[norms == 0] = 1\n",
    "    return X / norms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1776a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar tu dataframe (asegÃºrate de que estÃ© en tu entorno)\n",
    "train_df = pd.read_csv(\"train_df.csv\")  # Reemplaza con la ruta a tu archivo CSV\n",
    "df = train_df.copy()\n",
    "df = df.drop(columns=[\"paciente_id\"])         # 1. Eliminar ID\n",
    "df[\"genero\"] = df[\"genero\"].map({\"M\": 1, \"F\": 0})  # 2. Codificar genero\n",
    "\n",
    "X = df.drop(columns=[\"target\"])\n",
    "y = df[\"target\"].values.reshape(-1, 1)\n",
    "\n",
    "# 3. Estandarizar variables numÃ©ricas (menos 'genero')\n",
    "numeric_cols = X.columns.tolist()\n",
    "numeric_cols.remove(\"genero\")\n",
    "\n",
    "means = X[numeric_cols].mean()\n",
    "stds = X[numeric_cols].std()\n",
    "X[numeric_cols] = (X[numeric_cols] - means) / stds\n",
    "\n",
    "X_final = X.values  # X_final vuelve a existir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadcae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(X, y, val_ratio=0.2, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    m = X.shape[0]\n",
    "    indices = np.random.permutation(m)\n",
    "    val_size = int(m * val_ratio)\n",
    "    \n",
    "    val_idx = indices[:val_size]\n",
    "    train_idx = indices[val_size:]\n",
    "    \n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_val, y_val = X[val_idx], y[val_idx]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4cd076",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = train_val_split(X_final, y)\n",
    "theta, bias, losses = train_logistic_regression(X_train, y_train, lr=0.1, epochs=1000)\n",
    "y_val_pred = predict(X_val, theta, bias)\n",
    "f1_val = compute_f1_score(y_val.ravel(), y_val_pred.ravel())\n",
    "\n",
    "print(\"F1-Score en ValidaciÃ³n:\", f1_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d0dd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.05, 0.1, 0.2]\n",
    "epoch_list = [500, 1000, 2000]\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = (None, None)\n",
    "\n",
    "print(\"Probando combinaciones...\\n\")\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for epochs in epoch_list:\n",
    "        theta, bias, _ = train_logistic_regression(X_train, y_train, lr=lr, epochs=epochs)\n",
    "        y_val_pred = predict(X_val, theta, bias)\n",
    "        f1 = compute_f1_score(y_val.ravel(), y_val_pred.ravel())\n",
    "        \n",
    "        print(f\"lr = {lr}, epochs = {epochs} => F1-score: {f1:.4f}\")\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_params = (lr, epochs)\n",
    "\n",
    "print(\"\\nâœ… Mejor combinaciÃ³n:\")\n",
    "print(f\"Learning Rate: {best_params[0]}\")\n",
    "print(f\"Epochs: {best_params[1]}\")\n",
    "print(f\"F1-Score: {best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8b3f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_final, bias_final, _ = train_logistic_regression(X_final, y, lr=0.01, epochs=500)\n",
    "\n",
    "test_df = pd.read_csv(r\"C:\\Users\\dfqo2\\Desktop\\ALC\\Kaggle\\Proyecto2\\test_df.csv\")\n",
    "test_df = test_df.drop(columns=[\"paciente_id\"])  # Eliminar ID\n",
    "test_df[\"genero\"] = test_df[\"genero\"].map({\"M\": 1, \"F\": 0})  # Codificar genero\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluir columnas no numÃ©ricas o irrelevantes\n",
    "train_columns = [col for col in train_df.columns if col not in ['paciente_id', 'target']]\n",
    "\n",
    "# Dejar solo esas columnas en el test\n",
    "X_test = test_df[train_columns].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Rellenar valores faltantes\n",
    "X_test = X_test.fillna(X_test.mean())\n",
    "\n",
    "# Normalizar\n",
    "X_test_normalized = normalize(X_test.values.astype(np.float64))\n",
    "\n",
    "# AÃ±adir bias\n",
    "X_test_final = np.hstack([np.ones((X_test_normalized.shape[0], 1)), X_test_normalized])\n",
    "\n",
    "# Confirmar dimensiones\n",
    "print(\"X_test_final shape:\", X_test_final.shape)\n",
    "print(\"theta shape:\", theta.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24775c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "train_df = pd.read_csv(\"train_df.csv\")\n",
    "\n",
    "# Preprocesamiento\n",
    "df = train_df.copy()\n",
    "df[\"genero\"] = df[\"genero\"].map({\"M\": 1, \"F\": 0})  # Codificar genero\n",
    "paciente_ids = df[\"paciente_id\"].values  # Guardar IDs\n",
    "df = df.drop(columns=[\"paciente_id\", \"target\"])\n",
    "\n",
    "# NormalizaciÃ³n\n",
    "def normalize(X):\n",
    "    norms = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1\n",
    "    return X / norms\n",
    "\n",
    "# EstÃ¡ndarizaciÃ³n numÃ©rica (excepto 'genero')\n",
    "numeric_cols = df.columns.tolist()\n",
    "numeric_cols.remove(\"genero\")\n",
    "means = df[numeric_cols].mean()\n",
    "stds = df[numeric_cols].std()\n",
    "df[numeric_cols] = (df[numeric_cols] - means) / stds\n",
    "\n",
    "# Convertir a matriz\n",
    "X = df.values.astype(np.float64)\n",
    "X_normalized = normalize(X)\n",
    "\n",
    "# NO aÃ±adimos bias manualmente, el modelo ya lo tiene separado\n",
    "X_with_bias = X_normalized\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred_probs = sigmoid(np.dot(X_with_bias, theta_final) + bias_final)\n",
    "y_pred_labels = (y_pred_probs >= 0.5).astype(int).flatten()\n",
    "\n",
    "# Crear archivo de submission\n",
    "submission_df = pd.DataFrame({\n",
    "    \"paciente_id\": paciente_ids,\n",
    "    \"target\": y_pred_labels\n",
    "})\n",
    "\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"âœ… Archivo submission.csv guardado correctamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc4ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "best_f1 = 0\n",
    "best_thresh = 0.5\n",
    "\n",
    "y_val_probs = sigmoid(np.dot(X_val, theta) + bias)\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_thresh = (y_val_probs >= t).astype(int)\n",
    "    f1 = compute_f1_score(y_val.ravel(), y_pred_thresh.ravel())\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = t\n",
    "\n",
    "print(f\"âœ… Mejor threshold: {best_thresh:.2f} con F1-score: {best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc922b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def add_polynomial_features(X_array):\n",
    "    # Si no tenemos nombres de columnas, los inventamos: col_0, col_1, ...\n",
    "    num_features = X_array.shape[1]\n",
    "    column_names = [f\"col_{i}\" for i in range(num_features)]\n",
    "\n",
    "    # Convertir a DataFrame\n",
    "    X_df = pd.DataFrame(X_array, columns=column_names)\n",
    "\n",
    "    # Asumimos que no hay una columna \"genero\" ya codificada. Si la hay, podemos adaptarlo.\n",
    "    numeric_cols = X_df.columns.tolist()\n",
    "\n",
    "    # Crear nuevas caracterÃ­sticas\n",
    "    for col in numeric_cols:\n",
    "        X_df[f\"{col}_squared\"] = X_df[col] ** 2\n",
    "\n",
    "    for i in range(len(numeric_cols)):\n",
    "        for j in range(i+1, len(numeric_cols)):\n",
    "            col1 = numeric_cols[i]\n",
    "            col2 = numeric_cols[j]\n",
    "            X_df[f\"{col1}_x_{col2}\"] = X_df[col1] * X_df[col2]\n",
    "\n",
    "    return X_df\n",
    "\n",
    "# Aplicar\n",
    "X_poly_df = add_polynomial_features(X)\n",
    "\n",
    "# Normalizar (todas las columnas)\n",
    "columns_to_scale = X_poly_df.columns.tolist()\n",
    "means = X_poly_df[columns_to_scale].mean()\n",
    "stds = X_poly_df[columns_to_scale].std()\n",
    "X_poly_df[columns_to_scale] = (X_poly_df[columns_to_scale] - means) / stds\n",
    "\n",
    "# Convertir de nuevo a numpy para entrenamiento\n",
    "X_final_poly = X_poly_df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a42ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = train_val_split(X_final_poly, y)\n",
    "\n",
    "theta, bias, _ = train_logistic_regression(X_train, y_train, lr=0.1, epochs=1000)\n",
    "\n",
    "# Probar de nuevo thresholds\n",
    "y_val_probs = sigmoid(np.dot(X_val, theta) + bias)\n",
    "thresholds = np.arange(0.000001, 1, 0.0000001)   \n",
    "\n",
    "best_f1 = 0\n",
    "best_thresh = 0.0001\n",
    "\n",
    "for t in thresholds:\n",
    "    y_pred_thresh = (y_val_probs >= t).astype(int)\n",
    "    f1 = compute_f1_score(y_val.ravel(), y_pred_thresh.ravel())\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thresh = t\n",
    "\n",
    "print(f\"âœ… Mejor threshold con features extendidas: {best_thresh:.5f}, F1: {best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"âœ… Mejor threshold con features extendidas: {best_thresh:.10f}, F1: {best_f1:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4238a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f1_scores = []\n",
    "for t in thresholds:\n",
    "    y_pred_thresh = (y_val_probs >= t).astype(int)\n",
    "    f1 = compute_f1_score(y_val.ravel(), y_pred_thresh.ravel())\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Graficar el F1-score contra el threshold\n",
    "plt.plot(thresholds, f1_scores, marker='o')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('F1-score')\n",
    "plt.title('F1-score vs. Threshold')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db1ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_correlation(X, y):\n",
    "    \"\"\"\n",
    "    Calcula la correlaciÃ³n de Pearson entre cada columna de X y el vector y.\n",
    "    \"\"\"\n",
    "    mean_y = np.mean(y)\n",
    "    correlations = []\n",
    "    for i in range(X.shape[1]):\n",
    "        xi = X[:, i]\n",
    "        mean_xi = np.mean(xi)\n",
    "        numerator = np.sum((xi - mean_xi) * (y - mean_y))\n",
    "        denominator = np.sqrt(np.sum((xi - mean_xi)**2) * np.sum((y - mean_y)**2))\n",
    "        corr = numerator / (denominator + 1e-8)\n",
    "        correlations.append(corr)\n",
    "    return np.array(correlations)\n",
    "\n",
    "def select_top_features(X, y, top_k=10):\n",
    "    corrs = feature_correlation(X, y)\n",
    "    top_indices = np.argsort(np.abs(corrs))[-top_k:]\n",
    "    return X[:, top_indices], top_indices  # retorna tambiÃ©n los Ã­ndices para seguimiento\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c20536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos\n",
    "train_df = pd.read_csv(\"train_df.csv\")\n",
    "\n",
    "# --- Preprocesamiento de train_df ---\n",
    "train_df[\"genero\"] = train_df[\"genero\"].map({\"M\": 1, \"F\": 0})\n",
    "y = train_df[\"target\"].values.reshape(-1, 1)\n",
    "paciente_ids_train = train_df[\"paciente_id\"].values\n",
    "X_df = train_df.drop(columns=[\"paciente_id\", \"target\"])\n",
    "\n",
    "# Normalizar columnas numÃ©ricas (menos 'genero')\n",
    "numeric_cols = X_df.columns.tolist()\n",
    "numeric_cols.remove(\"genero\")\n",
    "means = X_df[numeric_cols].mean()\n",
    "stds = X_df[numeric_cols].std()\n",
    "X_df[numeric_cols] = (X_df[numeric_cols] - means) / stds\n",
    "\n",
    "# Convertir a numpy y normalizar L2\n",
    "X = X_df.values.astype(np.float64)\n",
    "X = normalize(X)\n",
    "\n",
    "# Features polinomiales\n",
    "X_poly_df = add_polynomial_features(X)\n",
    "\n",
    "# Normalizar features extendidas\n",
    "means_poly = X_poly_df.mean()\n",
    "stds_poly = X_poly_df.std()\n",
    "X_poly_df = (X_poly_df - means_poly) / stds_poly\n",
    "X_final_poly = X_poly_df.values\n",
    "\n",
    "# Entrenar el modelo final\n",
    "theta, bias = train_logistic_regression(X_final_poly, y, lr=0.1, epochs=1000)\n",
    "\n",
    "# Generar predicciones para los mismos datos de entrenamiento\n",
    "y_probs = sigmoid(np.dot(X_final_poly, theta) + bias)\n",
    "\n",
    "# Usar el mejor threshold encontrado\n",
    "best_thresh = 0.25\n",
    "y_preds = (y_probs >= best_thresh).astype(int).flatten()\n",
    "\n",
    "# Crear archivo de submission con train\n",
    "submission_df = pd.DataFrame({\n",
    "    \"paciente_id\": paciente_ids_train,\n",
    "    \"target\": y_preds\n",
    "})\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"âœ… submission.csv generado con threshold = 0.25 usando train_df.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ab413f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Mejor threshold encontrado: 0.310402 con F1-score: 0.665657\n",
      "âœ… submission.csv generado con features extendidas y threshold optimizado.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Funciones necesarias\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def normalize(X):\n",
    "    norms = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    norms[norms == 0] = 1\n",
    "    return X / norms\n",
    "\n",
    "def train_logistic_regression(X, y, lr=0.2, epochs=2000):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros((n, 1))\n",
    "    bias = 0\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        z = np.dot(X, theta) + bias\n",
    "        h = sigmoid(z)\n",
    "        error = h - y\n",
    "        grad_theta = np.dot(X.T, error) / m\n",
    "        grad_bias = np.mean(error)\n",
    "\n",
    "        theta -= lr * grad_theta\n",
    "        bias -= lr * grad_bias\n",
    "\n",
    "    return theta, bias\n",
    "\n",
    "def add_polynomial_and_cross_features_np(X):\n",
    "    \"\"\"\n",
    "    Agrega tÃ©rminos cuadrÃ¡ticos, cÃºbicos y cruzados usando solo numpy.\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    features = [X]\n",
    "\n",
    "    # Cuadrados y cubos\n",
    "    features.append(X ** 2)\n",
    "    features.append(X ** 3)\n",
    "\n",
    "    # Interacciones cruzadas (combinaciones Ãºnicas i < j)\n",
    "    cross_terms = []\n",
    "    for i in range(n_features):\n",
    "        for j in range(i + 1, n_features):\n",
    "            cross = (X[:, i] * X[:, j]).reshape(-1, 1)\n",
    "            cross_terms.append(cross)\n",
    "    if cross_terms:\n",
    "        features.append(np.hstack(cross_terms))\n",
    "\n",
    "    return np.hstack(features)\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    return f1\n",
    "\n",
    "def find_best_threshold(y_true, y_probs):\n",
    "    thresholds = np.linspace(0.01, 0.99, 200)\n",
    "    best_f1 = 0\n",
    "    best_thresh = 0.5\n",
    "    for thresh in thresholds:\n",
    "        preds = (y_probs >= thresh).astype(int)\n",
    "        f1 = f1_score(y_true, preds)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_thresh = thresh\n",
    "    return best_thresh, best_f1\n",
    "\n",
    "# === Cargar y procesar datos ===\n",
    "df = pd.read_csv(\"train_df.csv\")\n",
    "df[\"genero\"] = df[\"genero\"].map({\"M\": 1, \"F\": 0})\n",
    "y = df[\"target\"].values.reshape(-1, 1)\n",
    "paciente_ids = df[\"paciente_id\"]\n",
    "X_df = df.drop(columns=[\"paciente_id\", \"target\"])\n",
    "\n",
    "# NormalizaciÃ³n numÃ©rica\n",
    "numeric_cols = X_df.columns.tolist()\n",
    "numeric_cols.remove(\"genero\")\n",
    "means = X_df[numeric_cols].mean()\n",
    "stds = X_df[numeric_cols].std()\n",
    "X_df[numeric_cols] = (X_df[numeric_cols] - means) / stds\n",
    "\n",
    "# L2 normalization\n",
    "X = normalize(X_df.values.astype(np.float64))\n",
    "\n",
    "# Features polinomiales y cÃºbicas cruzadas\n",
    "X_poly = add_polynomial_and_cross_features_np(X)\n",
    "\n",
    "# NormalizaciÃ³n polinomial\n",
    "X_poly = (X_poly - X_poly.mean(axis=0)) / (X_poly.std(axis=0) + 1e-8)\n",
    "\n",
    "# Entrenar modelo\n",
    "theta, bias = train_logistic_regression(X_poly, y, lr=0.2, epochs=2000)\n",
    "\n",
    "# Predecir probabilidades\n",
    "y_probs = sigmoid(np.dot(X_poly, theta) + bias)\n",
    "\n",
    "\n",
    "\n",
    "# Buscar mejor threshold\n",
    "best_thresh, best_f1 = find_best_threshold(y.flatten(), y_probs.flatten())\n",
    "\n",
    "#best_thresh = 0.2715942\n",
    "\n",
    "print(f\"ðŸ“Š Mejor threshold encontrado: {best_thresh:.6f} con F1-score: {best_f1:.6f}\")\n",
    "\n",
    "# PredicciÃ³n final\n",
    "y_preds = (y_probs >= best_thresh).astype(int).flatten()\n",
    "\n",
    "# Guardar submission\n",
    "submission_df = pd.DataFrame({\n",
    "    \"paciente_id\": paciente_ids,\n",
    "    \"target\": y_preds\n",
    "})\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"âœ… submission.csv generado con features extendidas y threshold optimizado.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
